# ======================================
# Snakefile: Project processing, 
# running a single cell + epitope pair.
#
# If we want mail too:
# See https://www.cyberciti.biz/tips/linux-use-gmail-as-a-smarthost.html
# snakemake 2> snakemake.log
# mail -s "snakemake Finished" cboix@mit.edu < snakemake.log
# ======================================
import os
import config
import random
import csv

# TODO note that WCE files are still in EPIMAP_ANALYSIS dirs
# Arguments::
DBDIR = os.environ.get("DBDIR")
FILEINFO = os.environ.get("FILEINFO")
MAPPING = os.environ.get("MAPPING")  # ID TO CELL TYPE
PROJECT = os.environ.get("PROJECT")
EXPT = os.environ.get("EXPT")
TASK = int(os.environ.get("SGE_TASK_ID")) - 1

# Variables:
ASSEMBLIES= 'GRCh38|hg19'
RLEN = 36 # NOTE: currently standardized, but could change
MAPPABLE = config.MAP36 # paired with RLEN
if EXPT == "DNase-seq":
    NREADS = 50000000
else:
    NREADS = 30000000

# Get cell type mapping to BSSID
ct_map = {}
bss_map = {}
with open(MAPPING) as infile:
    reader = csv.reader(infile, delimiter="\t")
    for row in reader:
        ct_map[row[0]] = row[1]
        bss_map[row[1]] = row[0]

# Processing Information:
info = []
ce_dict = {}
with open(FILEINFO) as infile:
    reader = csv.DictReader(infile, delimiter="\t")
    for row in reader:
        info.append(row)
        bss = ct_map[row['cell_type']]
        ce = bss + "_and_" + row['epitope']
        if ce in ce_dict.keys():
            ce_dict[ce].append(row)
        else:
            ce_dict[ce] = [row]

# Get task information:
cell_epitopes = [k for k in ce_dict.keys()]
cell_epitopes.sort()
cell_epitope = cell_epitopes[TASK]
cell = cell_epitope.split("_and_")[0]
EPITOPE = cell_epitope.split("_and_")[1]
RUN_ID = PROJECT + "_" + str(EPITOPE) + "_" + str(TASK) + "_" + cell_epitope

print(cell_epitope)
print(bss_map[cell] + "(" + cell + ") and " + EPITOPE)

# Task information for all relevant files:
lines = ce_dict[cell_epitope]
links = [ l['file'] for l in lines ]
proc_states = [ l['output_type'] for l in lines ]
ids = [ l['id'] for l in lines ]
assemblies = [ l['assembly'] for l in lines ]
extensions = [ config.get_extension(link) for link in links ]
mapqs = [ config.get_mapq_thresh(status) for status in proc_states ] # MAPQ_THRESH

# Information on ENCODE files:
wce_map= {}
ct_info = {}
with open(config.WCE_MAPPING) as infile:
    reader = csv.reader(infile, delimiter="\t")
    for row in reader:
        ct_info[row[0]] = row[1]
        wce_map[row[0]] = row[2]

WCEcell = wce_map[cell]
print("Cell is: " + cell + " - " + ct_info[cell])
print("Control: " + WCEcell + " - " + ct_info[WCEcell])

# Directories:
MAINDIR = DBDIR + "/" + EXPT
EPDIR = MAINDIR + "/files/" + EPITOPE
CTRL_DIR = MAINDIR + "/files/WCE"
subdirs = [ "window_coverage", "peaks", "tagAlign", "bedgraph", "qc" ]
EPITOPE_DIRS = [ EPDIR + "/" + d for d in subdirs ]

# NOTE: ALL AFTER THIS HAS ALREADY BEEN DEFINED!

# Directories for converted data for ChromHMM/ChromImpute
CONVDIR = DBDIR+"/ChromImpute/converted/" + EPITOPE
BINBEDDIR = DBDIR+"/ChromHMM/binarized/" + EPITOPE
DIRS = config.DIRS + EPITOPE_DIRS + [CONVDIR, BINBEDDIR]
for dir in DIRS:
    config.check_mkdir(dir)

# TODO FIXME TO HAVE TMPDIR WORKING!
TMPDIR = config.TMP + "/" + RUN_ID
config.check_mkdir(TMPDIR)
print(TMPDIR)

# Prefixes:
STRID = [id + "_" + cell for id in ids ]
VALID_STRID='|'.join(STRID)
CPREF = ["{}_{}".format(s,a) for s,a in zip(STRID, assemblies) ]
PREFIX = [ EPDIR + "/tagAlign/" + c for c in CPREF ]
QC_PREFIX = [ EPDIR + "/qc/" + c for c in CPREF ]
LINK_FILES = [ EPDIR + "/tagAlign/{}.{}.link".format(p,e) for p,e in zip(PREFIX,extensions) ]
MAPQ_THRESH = dict(zip(STRID,mapqs))
LINKS = dict(zip(STRID,links))
EXT = dict(zip(STRID,extensions))

# ===============================================================
# Define required outputs for each step:
# Must require these to properly to run all steps of the pipeline
# ===============================================================
# STEP1 Outputs and Cleaning steps:
RAW_BAM_FILE = [ p + ".bam" for p in PREFIX ]
RAW_INDEX_FILE = [ p + ".bai" for p in PREFIX ]
SORTED_BAM = [ p + ".sorted.bam" for p in PREFIX ]
QUAL_QC = [ q + ".mapq.qc" for q in QC_PREFIX ] # MAPQ range in raw file
HEADER_QC = [ p + "_header.sam" for p in PREFIX ] # Header

# Filtering files:
FILT_BAM_PREFIX = [ p + ".filt.srt" for p in PREFIX ]
FILT_BAM_FILE = [ f + ".bam" for f in FILT_BAM_PREFIX ]
DUP_FILE_QC = [ q + ".filt.srt.dup.qc" for q in QC_PREFIX ] # QC file marking dups
UNMAPPED_QC = [ p + ".over.unmapped" for p,a in zip(PREFIX,assemblies) if a == 'GRCh38' ]

# Final BAM files:
FINAL_QC_PREFIX = [ q + ".filt.nodup.srt" for q in QC_PREFIX ]
FINAL_BAM_PREFIX = [ p + ".filt.nodup.str" for p in PREFIX ]
FINAL_BAM_FILE = [ ff + ".bam" for ff in FINAL_BAM_PREFIX ]
FINAL_BAM_INDEX_FILE = [ ff + ".bai" for ff in FINAL_BAM_PREFIX ]
FINAL_BAM_FILE_MAPSTATS = [ qq + ".flagstat.qc" for qq in FINAL_QC_PREFIX ]
PBC_FILE_QC = [ qq + ".pbc.qc" for qq in FINAL_QC_PREFIX ] # quality statistics

# Final TA files:
FINAL_TA_FILE = [ EPDIR + "/tagAlign/" + s + "_hg19.filt.nodup.str.SE.tagAlign.gz" for s in STRID ]
FINAL_STEP1_FILE= [ EPDIR + "/tagAlign/FINAL_" + s + '.tagAlign.gz' for s in STRID ]
READS_QC = [ EPDIR + "/qc/FINAL_" + s + '.numreads' for s in STRID ]

STEP1_BAM_OUTPUTS = QUAL_QC + DUP_FILE_QC + PBC_FILE_QC + FINAL_BAM_FILE_MAPSTATS + HEADER_QC
STEP1_BASE_OUTPUTS = READS_QC +  UNMAPPED_QC
STEP1_BAM_CLEAN = RAW_BAM_FILE + RAW_INDEX_FILE + SORTED_BAM + FILT_BAM_FILE + FINAL_BAM_FILE + FINAL_BAM_INDEX_FILE
STEP1_BASE_CLEAN = FINAL_TA_FILE
# FIXME - choose outputs carefully!
# if EXT == 'bam':
#     STEP1_OUTPUTS = STEP1_BASE_OUTPUTS + STEP1_BAM_OUTPUTS
#     STEP1_CLEAN = STEP1_BASE_CLEAN + STEP1_BAM_CLEAN
# elif EXT == 'tagAlign':
STEP1_OUTPUTS = STEP1_BASE_OUTPUTS
STEP1_CLEAN = STEP1_BASE_CLEAN

# ----------------------------
# STEP2 Variables and Outputs:
TMP_TA_FILE = [ EPDIR + "/tagAlign/FINAL_" + s + "tagAlign.tmp.gz" for s in STRID ]
CHROM_ARM_FILE = [ EPDIR + "/window_coverage/" + s + ".chrom_arm" for s in STRID ]
DHS_WINDOWS_FILE = [ EPDIR + "/window_coverage/" + s + ".DHS_windows" for s in STRID ]
TABFILES = expand(EPDIR + "/window_coverage/{strid}.occ.{window}.tsv",
                strid = STRID, window = config.WINDOWS)
STEP2_OUTPUTS = DHS_WINDOWS_FILE + CHROM_ARM_FILE
STEP2_CLEAN = FINAL_STEP1_FILE + TABFILES + TMP_TA_FILE

# --------------
# STEP3 Outputs:
# TODO DEFINE BETTER OUTPUTS FOR STEP3 - inc plots.
POOL_PREFIX = "FINAL_" + EPITOPE + "_" + cell
POOL_QC_PREFIX = EPDIR + "/qc/" + POOL_PREFIX
POOL_TA_PREFIX = EPDIR + "/tagAlign/" + POOL_PREFIX
FINAL_TA_FILE = POOL_TA_PREFIX + ".tagAlign.gz"
FINAL_SUB_FILE = POOL_TA_PREFIX + ".sub.tagAlign.gz"

# QC files
READS_POOLED_QC = POOL_QC_PREFIX + ".numreads"
READS_SUB_QC = POOL_QC_PREFIX + ".sub.numreads"
FRAGLENFILE = POOL_QC_PREFIX + ".sub.cc.qc"
STEP3_OUTPUTS = [ FINAL_SUB_FILE, FINAL_TA_FILE, READS_POOLED_QC, READS_SUB_QC, FRAGLENFILE ]

# ------------------------
# STEP4 Outputs + Cleaning
if EXPT == 'DNase-seq':
    CTRL_PREFIX = "Uniform_BKG_CONTROL_" + str(RLEN) + "_" + str(NREADS)
else:
    CTRL_PREFIX = "FINAL_WCE_" + WCEcell
CONTROL_FILE = CTRL_DIR + "/tagAlign/" + CTRL_PREFIX + ".tagAlign.gz"
COMP_PREFIX = POOL_PREFIX + ".sub_VS_" + CTRL_PREFIX # comparison
PEAK_PREFIX = EPDIR + "/peaks/" + COMP_PREFIX

# Peaks:
NARROW_PK = PEAK_PREFIX + ".narrowPeak.gz"
BROAD_PK = PEAK_PREFIX + ".broadPeak.gz"
GAPPED_PK = PEAK_PREFIX + ".gappedPeak.gz"
if EPITOPE == 'DNase-seq':
    STEP4_OUTPUTS = [ CONTROL_FILE, NARROW_PK, BROAD_PK, GAPPED_PK ]
else:
    STEP4_OUTPUTS = [ CONTROL_FILE , NARROW_PK ]
STEP4_CLEAN = [ COMP_PREFIX + ".sval",  PEAK_PREFIX + "_peaks.*", PEAK_PREFIX + "_summits.*",
                PEAK_PREFIX + ".broad_peaks.*", PEAK_PREFIX + ".broad_summits.*" ]

# -------------------------
# STEP5 Outputs + Cleaning:
SIGNAL_PREFIX = EPDIR + "/bedgraph/" + COMP_PREFIX
PILEUP_BDG = SIGNAL_PREFIX + "_treat_pileup.bdg"
LAMBDA_BDG = SIGNAL_PREFIX + "_control_lambda.bdg"
FC_PREFIX = SIGNAL_PREFIX + ".fc.signal"
LV_PREFIX = SIGNAL_PREFIX + ".pval.signal"
FC_BDG = FC_PREFIX + ".bedgraph.gz"
LV_BDG = LV_PREFIX + ".bedgraph.gz"

# STEP5b and 5c - ChromImpute and ChromHMM inputs:
CONV_FILES = [ CONVDIR + "/" + c + "_" + COMP_PREFIX + ".pval.signal.bedgraph.gz.wig.gz" for c in config.CHRS_noY ]
# FC_CONV_FILES = [ CONVDIR + "/" + c + "_" + COMP_PREFIX + ".fc.signal.bedgraph.gz.wig.gz" for c in config.CHRS ]
ALLCHR = ['full'] + config.CHRS_noY  # Collated + CHRS
BINBED_FILES1 = [ BINBEDDIR + "/" + cell + "_c_t.sub_" + c + "_binary.txt.gz" for c in ALLCHR ]
# Subsample both:
BINBED_FILES2 = [ BINBEDDIR + "/" + cell + "_c.sub_t.sub_" + c + "_binary.txt.gz" for c in ALLCHR ]
# Subsample neither:
BINBED_FILES3 = [ BINBEDDIR + "/" + cell + "_c_t_" + c + "_binary.txt.gz" for c in ALLCHR ]

if EPITOPE == 'DNase-seq':
    BINBED_FILES = BINBED_FILES1  + BINBED_FILES3  # No subsampled control:
else:
    BINBED_FILES = BINBED_FILES1  + BINBED_FILES2  + BINBED_FILES3


STEP5_OUTPUTS = [ CONV_FILES, BINBED_FILES]  #, LV_BDG, FC_BDG, FC_CONV_FILES ]
STEP5_CLEAN = [ PILEUP_BDG, LAMBDA_BDG, SIGNAL_PREFIX + "_tab.txt", POOL_TA_PREFIX + "_HMMtab.txt" ]

# ======
# Rules:
# ======
if EPITOPE == "DNase-seq":
    STEP_OUTPUTS = STEP1_OUTPUTS + STEP2_OUTPUTS + STEP3_OUTPUTS + STEP4_OUTPUTS + STEP5_OUTPUTS
else:
    STEP_OUTPUTS = STEP1_OUTPUTS + STEP3_OUTPUTS + STEP4_OUTPUTS + STEP5_OUTPUTS

rule all:
    input: DIRS, STEP_OUTPUTS

rule dirs:
    output: DIRS
    shell: "mkdir -p " + " ".join(DIRS)

rule process_pool:
    input: DIRS, STEP1_OUTPUTS, STEP3_OUTPUTS

rule clean:
    shell: "rm " + ' '.join(STEP1_CLEAN) + ' '.join(STEP2_CLEAN) + ' '.join(STEP4_CLEAN) + ' '.join(STEP5_CLEAN)

# ===================
# STEP1 - Preprocess:
# Preprocess and turn into tagAlign files:
# ===================
include: 'rules/BAMtoTA_download_preprocess.rules'

rule all_step1:
    input: STEP1_OUTPUTS
    message: "==> STEP1 - Download and Preprocess <=="
    shell: "echo $( du -sh {input} )"

rule test_step:
    input: FINAL_TA_FILE

rule clean_step1:
    shell: "rm " + ' '.join(STEP1_CLEAN)

# ===========================================
# STEP2 - Window Occupancy
# Compute windows occupancy for the dataset:
# ===========================================
include: 'rules/compute_window_occupancy.rules'

rule all_step2:
    input: STEP2_OUTPUTS
    message: "==> STEP2 - Get window occupancy <=="
    shell: "echo $( du -sh {input} )"

rule clean_step2:
    shell: "rm " + ' '.join(STEP2_CLEAN)

# ==========================================
# STEP3 - Pool, subsample, and perform SCCA:
# ==========================================
include: 'rules/pool_subsample_SCCA.rules'

rule all_step3:
    input: STEP3_OUTPUTS
    message: "==> STEP3 - Pool, subsample, and SCCA <=="
    shell: "echo $( du -sh {input} )"

# ================================
# STEP4 - Call Peaks using MACS2.1
# Calls Broad, Narrow, Gapped peaks
# ================================
include: 'rules/call_peaks_macs.rules'

rule all_step4:
    input: STEP4_OUTPUTS
    message: "==> STEP4 - Call peaks with MACS2.1 <=="
    shell: "echo $( du -sh {input} )"

rule clean_step4:
    shell: "rm " + ' '.join(STEP4_CLEAN)

# ===================================
# STEP5 - Generate Signal Tracks
# ---5b - Average BDG for Chromimpute
# ---5c - Binarize for to ChromHMM
# ===================================
include: 'rules/generate_signal_tracks_macs.rules'

rule all_step5:
    input: STEP5_OUTPUTS
    message: "==> STEP5 - Generate signal tracks with MACS2.1 <=="
    shell: "echo $( du -sh {input} )"

rule clean_step5:
    shell: "rm " + ' '.join(STEP5_CLEAN)

